\section*{Conclusion}
Au terme de cet article, une revue des différents portions d'un agent conversationnel complet a été accomplie. Nous avons mentionné qu'un intrant vocal pourrait être converti sous une forme textuelle grâce à l'utilisation d'une architecture \gls{tc}-\gls{dnn}-\gls{bilstm}-\gls{dnn}. Il a aussi mentionné que les composantes syntaxiques et sémantiques d'un texte pouvaient être extraire grâce à \texttt{word2vec} au niveau des mots ou de manière similaire avec \texttt{inferSent} au niveau des phrases. Les méchanismes d'attentions de (CITER LES SOURCES) pourront ensuite être exploités afin d’identifier l'information qui devra être retournée à l'utilisateur. Une fois en possession de cette information, celle-ci devra être intégré dans une réponse textuelle complète respectant les règles de la langue utilisée dans l'échange. C'est à ce moment que l'architecture \gls{hred} entrera en jeu pour générer un discours fluide et cohérent. En dernier lieu, la génération d'un signal sonore artificiel sera déléguée à l'architecture \texttt{Wavenet}. Avec un peu de travail pour combiner tous ces morceaux du casse-tête, un agent conversationnel performants en résultera. En guise de conclusion, nous remarquons encore une fois que les approches par réseaux de neurones dominent encore une fois la majorité des autres approches auparavant exploitées. Ce qui a de plus extraordinaire avec ces derniers, c'est que des problèmes qui peuvent sembler immensément complexe de prime abord se révèle à être beaucoup plus simples lorsque nous laissons les machines déterminer elles-mêmes les composantes et du signal à déduire des ces dernières via des solutions semi ou non-supervisées.
