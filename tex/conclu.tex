\section*{Conclusion}
Au terme de cet article, une revue des différentes portions d'un agent conversationnel complet a été accomplie. Nous avons introduit le sujet en abordant la conversion d'un intrant vocal sous une forme textuelle grâce à une architecture \gls{tc}-\gls{dnn}-\gls{bilstm}-\gls{dnn}. Il a aussi été mentionné que les composantes syntaxiques et sémantiques d'un texte pouvaient être extraire grâce à \texttt{word2vec} au niveau des mots ou de manière similaire avec \texttt{inferSent} au niveau des phrases. Les mécanismes d'attentions de \cite{attentionBasedApproaches}, \cite{attentionIsAllYouNeed} et \cite{attentionMechanism} pourront ensuite être exploités afin d’identifier l'information qui devra être retournée à l'utilisateur. Une fois en possession de cette information, celle-ci devra être intégrée dans une réponse textuelle complète respectant les règles de la langue utilisée dans l'échange. C'est à ce moment que l'architecture \gls{hred} entrera en jeu pour générer un discours fluide et cohérent. En dernier lieu, la génération d'un signal sonore artificiel sera déléguée à l'architecture \texttt{Wavenet}. Avec un peu de travail pour combiner tous ces sous-systèmes, un agent conversationnel performant en résultera. En guise de conclusion, nous remarquons que les approches par réseaux de neurones dominent encore une fois la majorité des autres approches auparavant exploitées. Ce qui a de plus extraordinaire avec ces derniers, c'est que des problèmes qui peuvent sembler, de prime abord, immensément complexes se révèlent à être beaucoup plus simples lorsque nous laissons les machines déterminer elles-mêmes les composantes et le traitement du signal à déduire en fonction de ces dernières via des solutions semi ou non-supervisées.
