\subsection{Extraction des composantes de l'intrant et des sources d'information à analyser}
\label{devel:embedding}
Une fois que la requête de l'utilisateur est convertie sous une forme textuelle facilement manipulable par un ordinateur, il est possible, dès lors, d'utiliser un \textit{embedding} induit par l'étape précédente. Une autre approche consiste à reprendre cette sortie pour ensuite la fournir à une nouvelle structure qui se chargera d'aller extraire de nouvelles composantes qui aideront certainement à obtenir de meilleurs résultats pour la suite du processus. \\

À ce stade, nous devons comprendre que le signal est encore purement textuel et nous n'avons pour seule information qu'une décomposition des mots qui forment la demande reçue. Cependant, les langages sont formés de davantage de subtilités qu'un simple enchaînement de mots les uns après les autres. En effet, chaque mot joue un rôle précis dans la structure de la phrase et apporte une nuance particulière au contexte générale de celle-ci ou encore du texte avec une plus faible portée. C'est exactement ce que les travaux de \cite{word2vec} visaient à faire. Ainsi, en 2013, ce groupe de chercheurs a fait la publication d'un article détaillant leur approche en comparant plusieurs modèles comprenant autant des approches classiques que des approches neurales. En plus de faire état de leurs travaux, ce groupe est aussi à l'origine d'outil qui est encore à ce jour considéré comme un incontournable: \texttt{word2vec}. \\

Malgré le fait que cet article porte sur les approches neurales, cet outil a plutôt prouvé que des modèles plus simplistes et classiques sont parfois plus appropriés. En ce qui concerne \texttt{word2vec}, ce dernier se fonde sur la combinaison de deux techniques nommées \gls{cbow} (\autoref{fig:cbow}) et \gls{skipgram} (\autoref{fig:skipgram}). Alors que le \gls{skipgram} se concentre à essayer de prédire le contexte environnant d'un mot donné, le \gls{cbow} cherchera plutôt à prédire la valeur considérée à partir de son environnement accordant ainsi plus d’importance à la structure des phrases plutôt qu’au contexte de son utilisation.\\

\begin{figure}[ht]
  \centering
  \includegraphics[width=\columnwidth, height=0.35\textheight, keepaspectratio]{cbow}
  \caption{Architecture de la méthode de prédiction \gls{cbow} [\citenum{word2vec}]}
  \label{fig:cbow}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\columnwidth, height=0.35\textheight, keepaspectratio]{skipgram}
  \caption{Architecture de la méthode de prédiction \gls{skipgram} [\citenum{word2vec}]}
  \label{fig:skipgram}
\end{figure}

En fournissant la requête reçue à cet outil, il est donc possible d'extraire les composantes sémantiques et syntaxiques sous-entendues dans cette dernière. Par la suite, ces nouvelles composantes seront combinées à celle déjà obtenues à l'étape précédente. En procédant avec cette seconde approche, un gain majeur est réalisé au niveau de la performance des étapes de modélisation subséquentes en raison de l'ajout de dimensionnalités qui fourniront beaucoup plus de flexibilité pour détecter les nuances du langage. À titre d'exemple, lorsqu'un utilisateur demandera à l'assistant si ce dernier peut lui indiquer l'horaire du cinéma le plus prêt de sa position, l'assistant devra comprendre la nuance que ce qui intéresse vraiment l'utilisateur est l'horaire et non pas l'évaluation booléenne de sa capacité à s'acquitter de cette tâche. Par contre, dans le cas où l'utilisateur demanderait à l'assistant si ce dernier peut le connecté à l'Internet, l'assistant devra dans ce cas faire l'évaluation de sa capacité et répondre par affirmation à ce cher utilisateur. \\

Mais qu'en est-il de nos sources d'informations? En fait, le processus entier bénéficiera qu'un travail similaire soit réalisé à ce niveau aussi. Pour ce faire, deux alternatives s'offrent encore à nous. La première consistant encore une fois à utiliser \texttt{word2vec} et la seconde repose sur le même principe, mais à un niveau supérieur d'abstraction en considérant cette fois l'utilité de chacune des phrases dans le texte plutôt que de se concentrer sur le rôle de chaque mot dans chaque phrase \cite{inferSent}. De plus, il est possible d'utiliser les représentations neurales intermédiaires du réseaux de neurones du système précédent dans le flût d'information afin d'y extraire des informations sur la personne qui parle provenant du contexte vocal plutôt que textuel. \\

En somme, toutes ces composantes ainsi dérivées pourront ensuite être fournies en entrée d'un réseau de neurones tel qu'un \gls{rnn} comme il est expliqué à section suivante. En effet, un \gls{rnn} peut lire des mots une fois les mots transformés en \textit{embedding}, ce qui est propice à une utilisation neurale de ces mots.
