\subsection{Interpréter la requête et cibler le contenu d'intérêt pour y répondre}
\label{devel:qa}

Pour analyser les demandes de l'utilisateur, il faut les traduire en requêtes neurales pour ensuite rechercher dans le texte les passages intéressants. Cela est une étape importante à comprendre avant d'analyser davantage ce qui sera expliqué dans les prochaines sections. C'est l'une des choses que peuvent faire les mécanismes d'attention tels qu'introduits par \cite{attentionMechanism}. Ces mécanismes sont illustrés à la \autoref{fig:attn}. Son fonctionnement va comme suit. En premier lieu, le texte est lu séquentiellement en entrée (en bas à gauche). Ensuite, une requête est faite pour filtrer ce qui est lu et faire l'alignement d'attention (en bas à droite). Cette requête peut provenir d'un autre réseau de neurones, mais est ici elle-même générée dans un contexte de traduction automatique. La requête est donc de demander par quoi la phrase devrait débuter lors de ce début de traduction, ce que le décodeur (à droite) peut utiliser pour construire mot par mot une phrase traduite avec une requête à chaque nouveau mot, séquentiellement. Cette requête est à chaque étape comparée à toute l'information à filtrer par le mécanisme d'attention (au centre). C'est ainsi qu'un résultat est formulé par ce calcul du mécanisme d'attention en fonction de la requête demandée (en haut). Les auteurs soutiennent que les mécanismes d'attention sont à explorer plus en profondeur et que cela n'est que leur début. Une certaine exploration de ce mécanisme est faite par \cite{attentionBasedApproaches}. Dans ce papier, ils définissent, entre autres choses, un tel mécanisme comme étant un mini réseau de neurones dans un plus gros. Ce mini réseau de neurones sert à déterminer où porter de l'attention, et peut prendre des formes variées, tel qu'un réseau de neurones linéaire à deux couches, ou bien une comparaison par produit vectoriel de chaque élément à comparer à la requête, en tant que mesure de similarité entre la requête et les éléments d'information où rechercher. \\

\begin{figure*}
  \centering
  \includegraphics[width=\textwidth, height=0.4\textheight, keepaspectratio]{bahdanauAttentionMechanism2014}
  \caption{Mécanisme d'attention sous sa forme générale, tel qu'introduit par \cite{attentionMechanism} et ici raffinés par \cite{attentionBasedApproaches} dans cette figure.}
  \label{fig:attn}
\end{figure*}

Il est bien d'utiliser des mécanismes d'attention pour faire de la traduction automatique \cite{attentionMechanism}, mais il est tout aussi possible de les utiliser pour trouver dans du texte les passages intéressants en fonction d'une question? C'est ce que font \cite{squad\string:attentionOverAttention}, tout comme \cite{squad\string:coattention} sur le jeux de données du SQuAD \cite{squad}, les deux approches s'inspirant des travaux de \textbf{Google}, lesquels sont détaillés à la section suivante, \cite{readNcomprehend}. Les travaux de Cui et al. sont illustrés à la \autoref{fig:coAttn}.

\begin{figure*}
  \centering
  \includegraphics[width=\textwidth, height=0.4\textheight, keepaspectratio]{squadAttentionOverAttention}
  \caption{Réseaux de neurones profonds permettant d'analyser un document (en haut à gauche) en fonction d'une requête (en bas à gauche) pour produire une réponse avec l'information trouvée (à droite) \cite{squad\string:attentionOverAttention}.}
  \label{fig:coAttn}
\end{figure*}
