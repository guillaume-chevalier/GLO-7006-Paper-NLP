\section{Introduction}

Depuis la naissance de l'informatique, l'humain a toujours convoité l'idée de pouvoir interagir verbalement avec un ordinateur, et ce, de manière transparente comme s'il s'agissait d'un autre humain apte à capter la majorité des nuances du discours entretenu. Les premières tentatives (\textbf{ELIZA} - \textit{the artificially-intelligent psychiatrist} \cite{elizaWeizenbaum} et \textbf{PARRY} - \textit{the paranoid computer}1 \cite{parryCerf}) ont cependant démontré que cette tâche était loin d'être simple et qu'aucun algorithme ne pourra éventuellement répondre parfaitement à cette tâche et ainsi satisfaire les exigences du test de \cite{turingTest}. Bien que ce sujet aura fait couler beaucoup d'encre et fait tourner les têtes, il n'existe toujours pas, à ce jour, une formule secrète parfaite pour parvenir à sa réalisation. Au cours des années, différentes démarches ont été proposées. Traditionnellement, des approches algorithmiques étaient favorisées et certains projets se fondent encore sur ces dernières, tel que \textbf{Watson (IBM)}\footnote{\url{https://www.ibm.com/watson/}} \cite{ibmWatson}. Ces approches ont toutefois le défaut d'être longues et ardues à développer. De plus, la réutilisation des travaux sous-jacents est plus complexe en raison du caractère sur-mesure de la solution étroitement liée au champ d'application spécifique, tel que de jouer à \textbf{Jeopardy} \footnote{\url{https://www.jeopardy.com/}}. Depuis 2014, ce approches classiques furent appelées à être remplacées par des approches fonctionnant par réseaux de neurones profonds, le point marquant de ce virage étant la découverte des mécanismes d'attention par \cite{attentionMechanism}. \\

De ce fait, des approches mettant en jeu des réseaux de neurones artificiels ont fait leur apparition et ont immédiatement connu beaucoup de succès. Une des premières démonstrations des capacités de ces approches se fit sur la traduction automatisée \cite{attentionMechanism}. De tels systèmes sont désormais utilisés chez \textbf{Google} pour la mise en production du fameux \textbf{Google Translate} \cite{googleTranslate}. Par surcroît, cette même compagnie utilise aussi des solutions neurales de \gls{tts} telles que celle proposée par \cite{acousticModeling} afin de pouvoir générer des sous-titres automatiquement pour des médias numériques \footnote{Comme \textbf{YouTube} le fait sur l'ensemble de ses vidéos pour suggérer du contenu à ses utilisateurs} et analyser ces derniers afin de les regrouper sous la forme d'un arbre sémantique. Il ne s'agit ici que de simples morceaux d'un puzzle entier, soit la création d'un agent conversationnel basé sur des réseaux de neurones. C'est justement l'assemblage de découvertes provenant de différents partis (tous ayant des objectifs distincts) qui rend la conception d'un tel agent aussi complexe et l'une des raisons pour laquelle le mouvement \textit{open-source} est si proéminent dans ce domaine. \\

Dans le cadre d'un échange verbal entre deux êtres, une multitude de tâches sont accomplies sans même en être conscients. Le tout débute lors d'un contact initial le plus souvent dans une forme sonore vers un destinataire. En partant de ce point, il faut premièrement capter le message, l'interpréter en mots et, malgré des obstacles environnants et culturels variés réduisant la qualité de cette transmission, filtrer ce qui est réellement important dans le signal tout en le décodant selon un dialecte particulier. C'est à cette étape que s'insèrent les architectures de \gls{stt}. Une fois en possession de ce message, il faut établir des liens entre l'énoncé qui a été donné et un registre de connaissances en plus de prendre en compte les discussions passées avec le même interlocuteur. C'est alors qu'il est possible d'établir la réponse la plus appropriée compte tenu d'une panoplie de facteurs comme l'identité de notre interlocuteur, son domaine de travail, son niveau d'éducation et même les valeurs qui sont partagées ou distinctes entre les deux partis. Cette phase implique des réseaux de neurones capables d'analyser du texte à partir d'une requête, tels que les systèmes basés sur des améliorations et une exploration des mécanismes d'attention \cite{attentionBasedApproaches} ensuite appliquées à cette nouvelle tâche, introduits dans les travaux de \cite{readNcomprehend}. L'attention étant maintenant bien attribuée dans le texte, il sera alors possible de générer une réponse de manière similaire à ce qui est présenté dans les recherches de \cite{chatbot\string:HRED} et de \cite{chatbot\string:LVHRED}.\\

Une fois cette réponse textuelle en main, il ne reste plus qu'à la convertir en audio, ce qui est dorénavant possible en temps réel avec une approche par réseaux de neurones convolutionnels. Un des outils les plus connus à cet effet est \texttt{Wavenet} par \cite{wavenet}. \footnote{Encore une fois développé chez \textbf{Google} pour faire du \gls{tts}, l'inverse du \gls{stt}} D'autre part, ce genre de systèmes est suffisamment flexible pour opérer en plusieurs langues si il est combiné à un module de traduction automatisée. Au final, cela demande beaucoup de données d'apprentissage. Pour rajouter encore plus de difficulté, ces étapes sont à faire dans un intervalle de temps très court. Heureusement, l'étape la plus longue est de faire apprendre aux réseaux de neurones ce qu'ils ont à apprendre, tâche pouvant être réalisée à priori et réutiliser à répétition une fois complétée. Ils seront ensuite très performants lors de l'étape d'inférence, où ils analyseront et génèreront réellement de l'information en production. \\
