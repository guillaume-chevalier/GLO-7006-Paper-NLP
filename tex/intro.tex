\section{Introduction}

Depuis la naissance de l'informatique, l'humain a toujours convoité l'idée de pouvoir intéragir verbalement avec un ordinateur, et ce, de manière transparente comme s'il s'agissait d'un autre humain apte à capter la majorité des nuances du discours entretenu. Les premières tentatives (ELIZA - \textit{the artificially-intelligent psychiatrist} \cite{elizaWeizenbaum} et PARRY - \textit{the paranoid computer}1 \cite{parryCerf}) ont cependant démontré que cette tâche était loin d'être simple et qu'aucun algorithme ne pourra éventuellement répondre parfaitement à cette tâche et ainsi être considérée suffisamment intelligente pour passer le test de Turing \cite{turingTest}. Bien que ce sujet aura fait couler beaucoup d'encre et fait tourner les têtes, il n'existe toujours pas à ce jour une formule secrète parfaite pour parvenir à sa réalisation. Au cours des années, différentes démarches ont été proposées. Traditionnellement, des approches algorithmiques étaient favorisées et certains projets se fondent encore sur ces dernières, tel que \textbf{Watson (IBM)}\footnote{\url{https://www.ibm.com/watson/}} \cite{ibmWatson}. Ces approches ont toutefois le défaut d'être longues et ardues à développer. De plus, la réutilisation des travaux sous-jacents est plus complexe en raison du caractère sur-mesure du problème, en lien avec le champ d'application spécifique, tel que de jouer à Jeopardy \footnote{\url{https://www.jeopardy.com/}}. Depuis 2014, ce type d'approche classique fut appelé à changer par des approches fonctionnant par réseaux de neurones profonds, le point marquant de ce virage étant la découverte des mécanismes d'attention par \cite{attentionMechanism}. \\

\textcolor{red}{De ce fait, des approches mettant en jeu des réseaux de neurones artificiels ont fait leur apparition et ont immédiatement connus beaucoup de succès. Le grand pas réalisé en 2014 fait en sorte que les techniques par réseaux de neurones profonds viennent à dépasser les performances des techniques classiques pour la tâche de faire de la traduction automatique \cite{attentionMechanism}. De tels systèmes qui sont désormais utilisés chez \textbf{Google} pour la mise en production du fameux \textbf{Google Translate} \cite{googleTranslate}, avec leur publication officielle d'une amélioration de cette architecture neurale plus tard en octobre 2016. Cette même compagnie utilise aussi des algorithmes de \gls{tts} tels que tels que celui de William Chan et Ian Lane \cite{acousticModeling} afin de pouvoir générer des sous-titres automatiquement pour de l'audio ou des vidéos (tels que \textbf{YouTube} le fait avec des recherches similaires) et afin de pouvoir analyser les vidéos et les lier entre elles avec une approche sémantique.} \\

Il ne s'agit ici que de différents morceaux de puzzle complet qui peuvent mener à la création d'un agent conversationnel complètement basé sur ces systèmes par réseaux de neurones. La création d'un tel agent est une tâche compliquée dû au fait qu'il faut assembler les découvertes des différentes parties, l'une des raisons pourquoi le mouvement open-source est si proéminent. Dans le cadre d'un échange verbal entre deux êtres, une multitude de tâches sont accomplies sans même que nous ne soyons conscient. Le tout débute lors d'un contact initial le plus souvent dans une forme auditive vers un destinataire. En partant de ce point, à titre de destinataire, il faut premièrement capter le message, l'interpréter en mots et, malgré des obstacles environnants et culturels variés réduisant la qualité de cette transmission, filtrer ce qui est réellement important dans le signal ainsi que le décoder selon un dialecte particulier. C'est à cette étape que s'insère les architectures de \textit{Speech-to-Text}. Une fois en possession de ce message, il faut établir des liens entre l'énoncé qui a été donné et un registre de connaissances en plus de prendre en compte les discussions passées avec le même interlocuteur. C'est alors qu'il est possible d'établir la réponse la plus appropriée compte tenu d'une panoplie de facteurs comme l'identité de notre interlocuteur, son domaine de travail et son niveau d'éducation, les valeurs qui sont partagées ou distinctes entre les deux parties. Cette phase implique des réseaux de neurones capables d'analyser du texte à partir d'une requête, tels que les systèmes basés sur des améliorations et une exploration des mécanismes d'attention \cite{attentionBasedApproaches} ensuite appliquées à cette nouvelle tâche, introduits dans les travaux de \cite{readNcomprehend}. L'attention étant maintenant bien attribuée dans le texte, il est ensuite possible de générer une réponse, tel qu'avec les recherches récentes de \cite{chatbot\string:HRED} et de \cite{chatbot\string:LVHRED}.\\

Une fois cette réponse textuelle en main, il ne reste qu'à la convertir en audio, ce qui est dorénavant possible de générer en temps réel avec une approche par réseaux de neurones convolutionnels tels que \texttt{Wavenet} \cite{wavenet} (encore une fois développé chez \textbf{Google} pour faire du \gls{tts}, l'inverse du \gls{stt}). L'un des obstacles à cela est lorsque les utilisateurs possèdent un accent fortement prononcé et qui est unique, et la différences dans les langues. Du moins, ce genre de systèmes est adaptable à plusieurs langues, et au moment où du texte est en possesion, il est possible de le traduire automatiquement. Au final, cela demande beaucoup de données d'apprentissage. Pour rajouter encore plus de difficulté, ces étapes sont à faire dans un interval de temps très rapide pour éviter les longs délais. Heureusement, l'étape la plus longue est de faire apprendre aux réseaux de neurones ce qu'ils ont à apprendre. Ils sont ensuite très performants lors de l'étape d'inférence, où ils analyse et génèrent réellement de l'information en production. \\
